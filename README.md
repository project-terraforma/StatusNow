# StatusNow - Place Status Classification

This project aims to classify whether a place (POI) is Open or Closed based on its metadata.

## Data

- `data/Season 2 Samples 3k Project Updated.parquet`: The dataset containing place samples with a balanced distribution (~60% Open / 40% Closed).
- `data/processed_for_ml.parquet`: The processed dataset with engineering features (generated by `process_data.py`).

## Scripts

- **`read_data.py`**: Reads and displays the raw parquet data schema and first few rows.
- **`inspect_data.py`**: Performs deep inspection of the data, checking for valid IDs, class balance, and feature correlations.
- **`process_data.py`**: The main ETL script. It reads the raw data, parses JSON fields, creates features (Confidence, One-Hot Categories, Contact Depth), and saves the result to `data/processed_for_ml.parquet`.
- **`experiment_runner.py`**: Runs 5-Fold Cross Validation on multiple models (Balanced Random Forest, XGBoost) and reports metrics.

## Setup

```bash
# Create and activate virtual environment
python3 -m venv .venv
source .venv/bin/activate

# Install dependencies
pip install duckdb pandas numpy pyarrow scikit-learn imbalanced-learn xgboost
```

## Usage

1. Inspect the raw data:
   ```bash
   python3 read_data.py
   python3 inspect_data.py
   ```
2. Generate features:
   ```bash
   python3 process_data.py
   ```
3. Run Model Experiments:
   ```bash
   python3 experiment_runner.py
   ```

## Model Experiments & Findings

We compared **Balanced Random Forest** vs **XGBoost** to predict if a place is closed based on static metadata (phone presence, website presence, Overture confidence score).

### Results (Balanced Accuracy)

| Model           | Balanced Acc | Performance Analysis                                                              |
| :-------------- | :----------- | :-------------------------------------------------------------------------------- |
| **Balanced RF** | **65.03%**   | **Best**. Powered by Source Signals (Msft/Meta presence) and category details.    |
| **XGBoost**     | 64.80%       | **Very Close**. Effectively tied with Random Forest on the optimized feature set. |

### Key Insights

1.  **The "Source" Signal**: The strongest predictor found was the **Number of Sources**. Open places average **1.9** sources (e.g., listed in both Meta & Microsoft datasets), while Closed places average **1.35**.
2.  **Dataset Balance**: The "Season 2" dataset (60% Open) allowed standard models to perform much better than on the previous imbalanced data.
3.  **Ceiling**: Despite deep feature engineering (parsing JSON sources, specific categories), accuracy tops out at **65%**. This suggests that 35% of closed places look _identically_ valid (have phones, websites, recent updates) as open places in the static data.
