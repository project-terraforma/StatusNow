# StatusNow - Place Status Classification

This project aims to classify whether a place (POI) is Open or Closed based on its metadata and derived mobility signals.

## Data

- `data/Season 2 Samples 3k Project Updated.parquet`: **PRIMARY DATASET** (10/90 split). Contains 3,000 place samples with baseline comparison data (~60% Open / 40% Closed).
- `data/Project C Samples.parquet`: Alternative dataset (60/40 split, 3,425 rows) from a different assignment. Can be used if helpful.
- `data/processed_for_ml.parquet`: The final processed dataset with all engineered features including **delta features** (generated by `process_data.py`).

### Final Schema (for Machine Learning)

The `processed_for_ml.parquet` file contains the following engineered features used to train the model:

| Column Name                              | Type  | Description                                                                       |
| :--------------------------------------- | :---- | :-------------------------------------------------------------------------------- |
| **Label**                                |       |                                                                                   |
| `open`                                   | int64 | Target variable (1 = Open, 0 = Closed).                                           |
| **Delta Features (Baseline vs Current)** |       | **NEW**. Captures CHANGE in digital presence over time.                           |
| `delta_confidence`                       | float | Change in confidence score (baseline ‚Üí current).                                  |
| `delta_num_websites`                     | int   | Net change in website count.                                                      |
| `delta_num_socials`                      | int   | Net change in social media links. **Strong predictor** (r=+0.18).                 |
| `delta_num_phones`                       | int   | Net change in phone numbers.                                                      |
| `has_lost_website`                       | int   | 1 if lost at least one website (22% of closed vs 13% of open).                    |
| `has_gained_website`                     | int   | 1 if gained at least one website.                                                 |
| `has_lost_social`                        | int   | 1 if lost social media presence (59% of closed vs 45% of open).                   |
| `has_gained_social`                      | int   | **STRONGEST PREDICTOR** (r=+0.26). 1 if gained social media.                      |
| `has_lost_phone`                         | int   | 1 if lost phone number.                                                           |
| `has_gained_phone`                       | int   | 1 if gained phone number.                                                         |
| `delta_total_contact`                    | int   | Total change across all contact methods. **Strong indicator** (r=+0.19).          |
| `has_any_loss`                           | int   | 1 if lost ANY digital presence. **Strong closure signal** (r=-0.17).              |
| **Recency & Sources**                    |       |                                                                                   |
| `days_since_latest_update`               | int   | Days since the most recent source update (e.g., Meta/Msft update time).           |
| `avg_days_since_update`                  | float | Average age of all source records.                                                |
| `num_sources`                            | int   | Total count of datasets verifying this place (e.g., Meta + Microsoft = 2).        |
| `source_has_msft`                        | int   | 1 if 'Microsoft' is a source provider (High quality signal).                      |
| `is_cross_verified`                      | int   | 1 if the place appears in multiple independent datasets.                          |
| **Digital Presence**                     |       |                                                                                   |
| `has_website`                            | int   | 1 if a website URL is present.                                                    |
| `has_social`                             | int   | 1 if any social media link is present.                                            |
| `has_phone`                              | int   | 1 if a phone number is present.                                                   |
| `contact_depth`                          | int   | Sum of websites, socials, and emails (richness of contact info).                  |
| `len_socials`                            | int   | Count of social media handles.                                                    |
| `has_facebook`                           | int   | 1 if a Facebook URL is detected.                                                  |
| `has_instagram`                          | int   | 1 if an Instagram URL is detected.                                                |
| `has_conflicting_websites`               | int   | 1 if multiple distinct domain names are listed (potential confusion/closure).     |
| **Metadata**                             |       |                                                                                   |
| `confidence`                             | float | Overture's internal confidence score (0.0 - 1.0).                                 |
| `is_brand`                               | int   | 1 if the place is associated with a known brand chain.                            |
| `cat_is_unknown`                         | int   | 1 if the primary category is missing or 'unknown'.                                |
| **Categories (One-Hot)**                 | bool  | Specific category flags (e.g., `cat_hotel`, `cat_restaurant`, `cat_gas_station`). |

## Repository Structure

> **üìñ Need help navigating? See [NAVIGATION.md](NAVIGATION.md) for a complete guide!**

The repository is organized into clear categories:

### Data Processing Scripts (`scripts/data_processing/`)

- **`read_data.py`**: Quick data inspection - shows schema and first rows
- **`inspect_data.py`**: Deep data quality analysis - validates IDs, checks balance, correlations
- **`process_data.py`**: **V1 Pipeline** - Creates delta features ‚Üí `data/processed_for_ml.parquet`
- **`process_data_v2.py`**: **V2 Pipeline** - Advanced features ‚Üí `data/processed_for_ml_v2.parquet`
- **`process_data_v3.py`**: **V3 Pipeline ‚≠ê LATEST** - V2 + recency decay binning + brand-aware features ‚Üí `data/processed_for_ml_v3.parquet`
  - All V2 features (interaction, category churn risk, PCA, congruence)
  - Recency staleness flags (`is_stale_6mo`, `is_stale_1yr`, `is_stale_2yr`)
  - Log-transformed recency + ordinal recency bucket
  - Brand-aware interactions (`brand_x_stale`, `nonbrand_stale_risk`)
  - Optional: `--merge` flag to combine datasets

### Experiment Scripts (`scripts/experiments/`)

- **`experiment_runner.py`**: V1 experiments - 5-Fold CV on delta features
- **`experiment_runner_v2.py`**: V2 experiments - V1 vs V2 comparison
- **`experiment_runner_v3.py`**: **V3 Experiments ‚≠ê LATEST** - Label refinement + brand-stratified analysis + full V2‚ÜíV3 comparison

### Analysis Scripts ( `scripts/analysis/`)

- **`analyze_delta_features.py`**: Correlation analysis of delta features
- **`feature_selection.py`**: Identifies redundant features, finds optimal 30-feature subset

### Documentation (`docs/`)

- **`recommended_features.txt`**: Optimal 30 features for reduced overfitting
- **`summaries/BREAKTHROUGH_V2_RESULTS.md`**: V2 feature engineering summary
- **`summaries/DELTA_FEATURES_SUMMARY.md`**: Delta features deep dive
- **`summaries/MODEL_COMPARISON.md`**: All models compared

## Setup

```bash
# Create and activate virtual environment
python3 -m venv .venv
source .venv/bin/activate

# Install dependencies (Standard + Spatial)
pip install duckdb pandas numpy pyarrow scikit-learn imbalanced-learn xgboost fused geopandas shapely requests tqdm
```

## Usage

### Quick Start (V2 - Recommended) ‚≠ê

```bash
# 1. Process data with advanced features
python scripts/data_processing/process_data_v2.py

# 2. Run experiments and see the breakthrough
python scripts/experiments/experiment_runner_v2.py
```

### Complete Workflow

```bash
# 1. Inspect raw data (optional)
python scripts/data_processing/read_data.py
python scripts/data_processing/inspect_data.py

# 2. Analyze Delta Features (optional)
python scripts/analysis/analyze_delta_features.py

# 3. Generate V1 features
python scripts/data_processing/process_data.py

# 4. Run V1 experiments
python scripts/experiments/experiment_runner.py

# 5. Feature selection analysis (optional)
python scripts/analysis/feature_selection.py

# 6. Generate V2 features with advanced engineering ‚≠ê
python scripts/data_processing/process_data_v2.py

# 7. Run V2 experiments and see improvement ‚≠ê
python scripts/experiments/experiment_runner_v2.py

# 8. Optional: Merge datasets for more training data
python scripts/data_processing/process_data_v2.py --merge
```

## Model Experiments & Findings

We trained multiple models to predict if a place is closed, using **delta features** (baseline vs current comparison) alongside metadata, recency, and digital presence signals.

### Dataset Information

- **Primary**: Season 2 Samples 3k (10/90 split) - 3,000 rows
- **Features**: 49 total (including 12 delta features)
- **Class Balance**: 60.3% Open, 39.7% Closed
- **Key Innovation**: Delta features comparing baseline historical data with current data

### ÔøΩ LATEST: V3 Results (Label Refinement + Brand Analysis)

**72.09% balanced accuracy!** By cleaning mislabeled data and adding brand-aware features, we broke through the 72% barrier:

| Version      | Model               | Balanced Acc | ROC AUC    | F1 Macro   | Œî from V1  |
| :----------- | :------------------ | :----------- | :--------- | :--------- | :--------- |
| **V3+Clean** | **CatBoost** ‚≠ê     | **0.7209**   | **0.8167** | **0.7170** | **+7.10%** |
| V3+Clean     | XGBoost             | 0.7092       | 0.8227     | 0.7154     | +7.47%     |
| V3+Clean     | Logistic Regression | 0.7014       | 0.7837     | 0.6904     | +5.33%     |
| V3           | CatBoost            | 0.7056       | 0.7809     | 0.7024     | +4.83%     |
| V2           | CatBoost            | 0.7065       | 0.7842     | 0.7033     | +4.97%     |

**What V3 Added:**

- **Dynamic Label Refinement**: Cross-validated mislabel detection removed 65 suspect samples (2.2%) where the model was 90%+ confident the label was wrong ‚Üí **+1.44% balanced accuracy** instantly
- **Brand-Stratified Analysis**: Revealed a -5.23% accuracy gap between brands (63.86%) vs non-brands (69.09%), confirming micro-ensembling potential
- **Recency Decay Binning**: `is_stale_6mo`, `is_stale_1yr`, `is_stale_2yr` flags + log-transform + `brand_x_stale` interaction

### V2 Results (Advanced Feature Engineering)

| Model               | V1 Balanced Acc | V2 Balanced Acc | Improvement |
| :------------------ | :-------------- | :-------------- | :---------- |
| CatBoost            | 0.6731          | 0.7065          | +4.97%      |
| XGBoost             | 0.6599          | 0.6931          | +5.03%      |
| Logistic Regression | 0.6659          | 0.6846          | +2.80%      |

### V1 Results (Delta Features Only)

| Model               | ROC AUC | Balanced Acc | F1 Macro | Precision (Closed) | Recall (Closed) |
| :------------------ | :------ | :----------- | :------- | :----------------- | :-------------- |
| CatBoost            | 0.7559  | 0.6731       | 0.6645   | 0.5726             | 0.6834          |
| XGBoost             | 0.7601  | 0.6599       | 0.6629   | 0.6720             | 0.4702          |
| Logistic Regression | 0.7323  | 0.6659       | 0.6502   | 0.5903             | 0.7221          |
| Balanced RF         | 0.7382  | 0.6548       | 0.6366   | 0.5315             | 0.7380          |
| EasyEnsemble        | 0.7181  | 0.6502       | 0.6384   | 0.5423             | 0.6868          |

### Key Insights

#### V2 Advanced Features (What Drove the Breakthrough)

1. **Interaction Features Unlock Performance**: Capturing temporal relationships pushed past the 67% ceiling
   - **`recency_x_loss`**: Recent digital presence loss is a much stronger signal than old losses
   - **`zombie_score`**: num_sources / avg_days_since_update identifies "database purgatory" (high sources but very stale data)
   - **`decay_velocity`**: Rate of digital footprint decline
   - **`confidence_momentum`**: How quickly confidence is changing over time

2. **Category-Specific Risk Modeling**: Same signal means different things for different industries
   - **`category_churn_risk`**: Gas stations have ~10% churn, boutiques have ~45% churn
   - Losing a website matters MORE for high-churn categories
   - Industry context significantly improved precision

3. **PCA Reduces Overfitting**: Replaced 2 highly correlated recency features (r=0.97) with 1 PCA component
   - **Explained variance**: 98.68%
   - Prevented "double counting" of data age
   - Improved generalization

4. **Digital Congruence**: Website domain matching social handles = brand consistency signal

#### V1 Delta Features Foundation

5. **Delta Features Remain Critical**: Baseline vs current comparison is the foundation
   - **`has_gained_social`** (r=+0.26) - Still the strongest single predictor
   - **`has_any_loss`** (r=-0.17) - Strong closure signal
   - **`delta_total_contact`** (r=+0.19) - Overall change in digital footprint

6. **CatBoost Dominates**: 72.09% balanced accuracy with V3+Clean features ‚Äî best overall model

7. **Generalizability**: Model uses NO mobility data, applicable worldwide with Overture Maps data

8. **Breaking the Ceiling**: V2 features addressed the "Zombie POI" problem, V3 label cleaning tackled the noise floor

#### V3 Label Refinement & Brand Analysis

9. **Label Noise is Real**: 65 samples (2.2%) had high-confidence mislabels ‚Äî removing them gave an instant +1.44% boost

10. **Brands Behave Differently**: Branded POIs (Starbucks, Shell) are harder to classify (63.86% BalAcc) vs non-branded (69.09%) ‚Äî a micro-ensemble could exploit this -5.23% gap

11. **High-Churn Categories are Easier**: Categories with higher closure rates (70.45% BalAcc) are more predictable than low-churn ones (63.28%)

### Top Predictive Features

1. `has_gained_social` (+0.26 correlation) - Gained social media ‚Üí Open
2. `delta_total_contact` (+0.19) - Positive contact info change ‚Üí Open
3. `delta_num_socials` (+0.18) - More social media ‚Üí Open
4. `has_any_loss` (-0.17) - Lost any digital presence ‚Üí Closed
5. `delta_confidence` (+0.17) - Confidence increase ‚Üí Open

### Feature Selection Analysis

To avoid overfitting (49 features on 3,000 samples), we performed feature selection analysis:

**Key Findings:**

- ‚ö†Ô∏è **7 near-zero variance features** found (e.g., `has_instagram`, `has_conflicting_websites`)
- ‚ö†Ô∏è **15 highly correlated pairs** (r > 0.9) indicating redundancy:
  - `has_social` ‚Üî `has_facebook` (r=1.0) - perfectly correlated
  - `has_social` ‚Üî `len_socials` (r=1.0) - redundant
  - `has_website` ‚Üî `has_lost_website` (r=-0.94) - inverse relationship
  - `days_since_latest_update` ‚Üî `avg_days_since_update` (r=0.97) - highly redundant

**Optimal Feature Set: 30 features** üéØ

- **Performance**: 0.6782 balanced accuracy (vs 0.6738 with 48 features)
- **Improvement**: +0.43% by removing 18 redundant/low-importance features
- **Reduced overfitting**: Better generalization with fewer features

**Top 10 Most Important Features (by Random Forest):**

1. `avg_days_since_update` (14.6%)
2. `delta_confidence` (12.5%)
3. `days_since_latest_update` (10.5%)
4. `confidence` (9.8%)
5. `num_sources` (5.6%)
6. `delta_num_socials` (4.6%)
7. `delta_total_contact` (3.6%)
8. `is_brand` (3.2%)
9. `cat_other` (3.1%)
10. `source_has_msft` (3.0%)

**Features to Remove (9 lowest importance):**

- `has_instagram`, `has_conflicting_websites` (zero variance/importance)
- `has_gained_phone`, `has_lost_phone`, `delta_num_phones` (phones rarely change)
- `has_lost_website`, `has_gained_website` (redundant with delta features)
- Category features: `cat_landmark_and_historical_building`, `cat_automotive_repair`

See `recommended_features.txt` for the complete 30-feature list.

### Recommendations

- **For Production**: Use **CatBoost with V3+Label Cleaning** (72.09% balanced accuracy, 0.8167 ROC AUC) üèÜ
- **For Interpretability**: Use Logistic Regression V3+Clean (70.14% balanced accuracy)
- **For Precision**: Use XGBoost V3+Clean (70.92% balanced accuracy, 0.8227 ROC AUC ‚Äî best AUC overall)
- **To Merge More Data**: Run `python scripts/data_processing/process_data_v3.py --merge` to combine datasets
- **For Brands vs Non-Brands**: Consider a micro-ensemble with separate models per segment

### Advanced Features (V2) Summary

The breakthrough came from 10 new features across 4 categories:

1. **Interaction Features (5)**:
   - `recency_x_loss`, `recency_x_social_loss` - Temporal context matters
   - `zombie_score` - Database purgatory detection
   - `decay_velocity`, `confidence_momentum` - Rate of change signals

2. **Category Risk (1)**:
   - `category_churn_risk` - Industry-specific closure rates

3. **Digital Consistency (1)**:
   - `digital_congruence` - Website/social handle matching

4. **PCA Dimensionality Reduction (1)**:
   - `recency_pca` - Replaced 2 correlated features (98.68% variance explained)

## Journey Summary: From Baseline to Breakthrough

1. **Baseline Approach**: Traditional features (confidence, categories, sources) ‚Üí ~64% balanced accuracy
2. **Delta Features (V1)**: Added baseline vs current comparison ‚Üí **67.3% balanced accuracy** (+3.3%)
3. **Feature Selection**: Identified 30 optimal features, removed redundancy ‚Üí **67.8% on subset** (+0.5%)
4. **Advanced Engineering (V2)**: Interaction features + category risk + PCA ‚Üí **70.65% balanced accuracy** (+2.85%)
5. **Label Refinement (V3)**: Dynamic mislabel detection + brand-aware features ‚Üí **üèÜ 72.09% balanced accuracy (+1.44%, total +8.09% from baseline)**

### What We Learned

- **Temporal context matters most**: When digital presence changed is as important as what changed
- **Industry differences are real**: Gas stations ‚â† Boutiques in terms of closure signals
- **Redundancy hurts**: Perfect correlation (r=1.0) between features means wasted model capacity
- **"Zombie POIs" are solvable**: High source count + stale data = strong closure signal
- **Generalization is possible**: No mobility data required, applicable worldwide
- **Label noise is the hidden enemy**: Removing just 2.2% of mislabeled data boosted accuracy by 1.44%
- **Brands ‚â† Non-brands**: A 5.23% accuracy gap suggests different classification strategies are needed

### Next Steps (Optional)

1. **Micro-ensemble**: Train separate brand vs non-brand models to exploit the 5.23% accuracy gap
2. **Scale up**: Merge Project C dataset with `python scripts/data_processing/process_data_v3.py --merge` ‚Üí ~6,400 samples
3. **Hyperparameter tuning**: Grid search on CatBoost (V3+Clean) could push to 73%+
4. **Ensemble**: Stack CatBoost + XGBoost for final predictions
5. **Deploy**: Package V3 model for production use
